{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Main built-in LCEL functions for runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46ff75-72ab-4391-904f-459bae77fc7a",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* .bind()\n",
    "* .assign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* mkdir your_project_name\n",
    "* cd your_project_name\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f9e964-c5c2-4a13-b9ed-c449362ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **lcelZeroToMaster**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b5d23-5d09-4c88-b32f-3299795cd91b",
   "metadata": {},
   "source": [
    "## LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a34484-0981-4edc-8ba2-7c8521d28c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181ba6bd-cf77-43e0-8eb9-0c8e274b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb069f5-558d-4494-830d-958aa4f78ef3",
   "metadata": {},
   "source": [
    "* The \"pipe\" operator `|` is the main element of the LCEL chains.\n",
    "* The order (left to right) of the elements in a LCEL chain matters.\n",
    "* An LCEL Chain is a Sequence of Runnables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246e32f8-4380-41d2-b33a-04ff4085569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Cristiano Ronaldo is that he has his own museum dedicated to his career and achievements in his hometown of Funchal, Madeira, Portugal. The museum showcases memorabilia, trophies, and other items related to his successful career in football.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1026d5-2e99-4fd4-af2a-ac2c6d2eeeac",
   "metadata": {},
   "source": [
    "* All the components of the chain are Runnables.\n",
    "* When we write chain.invoke() we are using invoke with all the componentes of the chain in an orderly manner:\n",
    "    * First, we apply .invoke() to the prompt.\n",
    "    * Then, with the previous output, we apply .invoke() to the model.\n",
    "    * And finally, with the previous output, we apply .invoke() to the output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cbddb-7adc-44c2-847a-bfd6e0907b10",
   "metadata": {},
   "source": [
    "## Use of .bind() to add arguments to a Runnable in a LCEL Chain\n",
    "* For example, we can add an argument to stop the model response when it reaches the word \"Ronaldo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd686bcb-b128-4bdb-b34e-a585c1f2ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model.bind(stop=[\"Ronaldo\"]) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f9c195f-2c4e-4b36-ba44-c4b1ec1f7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a148eb-565d-4dfe-9d3c-062ed2c67468",
   "metadata": {},
   "source": [
    "## Use of .bind() to call an OpenAI Function in a LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56716892-6b51-4f03-949d-c770a6832ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"soccerfacts\",\n",
    "      \"description\": \"Curious facts about a soccer player\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"question\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The question for the curious facts about a soccer player\"\n",
    "          },\n",
    "          \"answer\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The answer to the question\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e498d3-3cf0-4948-85a3-65ea358015d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "chain = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"soccerfacts\"}, functions= functions)\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60ea942-ce8a-4f9e-99f2-6e5d45ca0edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a curious fact about Kylian Mbappe?',\n",
       " 'answer': 'Kylian Mbappe became the youngest French player to score in a World Cup at the age of 19 during the 2018 FIFA World Cup.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"soccer_player\": \"Mbappe\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cb212-3a91-479a-829e-c17d12d76e85",
   "metadata": {},
   "source": [
    "## The assign() function allows adding keys to a chain\n",
    "* Example: we will create a key name \"operation_b\" assigned to a custom function with a RunnableLambda.\n",
    "* We will start with a very basic chain with just RunnablePassthrough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7335550-2628-468a-b687-d9aa96294d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "chain = RunnableParallel({\"original_input\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff74a9e-ef49-4a98-b5a9-3da5b5c21d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_input': 'whatever'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"whatever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99966bbe-f9fe-4ede-b8f1-ae7d5c529c1e",
   "metadata": {},
   "source": [
    "* As you can see, right now this chain is only assigning the user input to the \"original_input\" variable.\n",
    "* Let's now add the new key \"uppercase\" with the assign function.\n",
    "* In the new \"uppercase\" key, we will use a RunnableLambda with the custom function named `make_uppercase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5498c91c-548f-4bb3-acca-90927ab5d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uppercase(arg):\n",
    "    return arg[\"original_input\"].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a69f270-a09d-48ea-8787-c313d1f88e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"original_input\": RunnablePassthrough()}).assign(uppercase=RunnableLambda(make_uppercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99e646ef-8e1f-450f-b5cd-395affae83b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_input': 'whatever', 'uppercase': 'WHATEVER'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"whatever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1622bcb-0bd3-4e19-bb26-cdcd5b27eabc",
   "metadata": {},
   "source": [
    "* As you can see, the output of the chain has now 2 keys: original_input and uppercase.\n",
    "* In the uppercase key, we can see that the `make_uppercase` function has been applied to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03829ba3-5b48-4be7-8181-3f2d91804a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
