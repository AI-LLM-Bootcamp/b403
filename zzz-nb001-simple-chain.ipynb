{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Simple Chain\n",
    "* Perform several actions in a particular order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759d27a-94f3-4141-945d-065f2095bffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intro\n",
    "* Chains are sequences of actions with input or output data.\n",
    "* Since the emmergence of LCEL, LangChain is favouring LCEL chains over Traditional (Legacy) Built-in Chains, but these are still maintained and frequently used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## LangChain documentation on Chains\n",
    "* See the LCEL documentation page on Chains [here](https://python.langchain.com/v0.2/docs/how_to/sequence/).\n",
    "* See the Legacy documentation page on Chains [here](https://python.langchain.com/v0.1/docs/modules/chains/). In this page you can see a list of the main built-in legacy chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58923013-1495-4d13-9c1c-36aaabd01cbe",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643efb6-e0f5-441e-9b69-56a8bce29dc3",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 001-simple-chain.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d2f8a-9d7c-4241-b078-f6470d25c8ef",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **001-simple-chain**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98f20c-eb25-4ef9-b94e-151c8c02fa3d",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdea43-eb87-45bf-a7a8-cbddbff7e309",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c1cf4-8675-47bc-bf75-9297c48f1d11",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87473364-f143-4516-a694-d1b5fafff6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf27d49-2f43-4368-aec2-75b829855b6a",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd81c2-5344-45d6-a1c8-f0c72aa81a09",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe4f83-d97e-4b96-a76d-a673e5ca9dac",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e141a5-ba40-4531-81d4-6e23c085dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {politician}\")\n",
    "\n",
    "chain = prompt | chatModel | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1387cd5-cd49-461d-85e8-395449724520",
   "metadata": {},
   "source": [
    "**What does StrOutputParser do?**\n",
    "   - The `StrOutputParser` is a specific tool within LangChain that simplifies the output from these language models. It takes the complex or structured output from the models and converts it into plain text (a string). This makes it easier to use this output in applications, like displaying it to users or processing it further for other purposes.\n",
    "\n",
    "**Specific Functions of StrOutputParser:**\n",
    "   - **For LLM Outputs:** If a language model produces output that is already in text form, `StrOutputParser` doesnâ€™t change it; it just passes it through.\n",
    "   - **For ChatModel Outputs:** If the output comes from a ChatModel (a type of language model designed for conversation), `StrOutputParser` extracts the main content from the structured output to make sure it ends up as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cadcb2d2-69b0-424e-a81a-d2c1eaa0ceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about JFK is that he was the first U.S. president to have been born in the 20th century. He was born on May 29, 1917, making him the first president born after the turn of the century.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"politician\": \"JFK\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763e8d3-7718-490c-9db1-1a8a2ad2a130",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-simple-chain.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-simple-chain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6e014-9a2d-4fc8-8319-945cd41b086a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
